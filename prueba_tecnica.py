# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1x9ym_oBhJPCkvsEWUeN85o7nSyq1mzIY

#### Importar las librerias necesarias
"""

import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# Se leen los conjuntos de train y test
train_df=pd.read_csv("train.csv", sep=';')
test_df=pd.read_csv("test.csv", sep=';')

"""#### Análisis exploratorio de los datos (con el fin de elegir las mejores caracteristicas para el modelo final, el tratamiento de datos faltantes y las variables categóricas)"""

# Se revisa la información del conjunto test, para ver cuantos datos tiene, cuantas variables conforman el ds y el tipo de variables.
test_df.info()

# Se revisa la información del conjunto train, para ver cuantos datos tiene, cuantas variables conforman el ds y el tipo de variables.
train_df.info()

#Se revisan cuantos datos tiene cada variable numérica, la mediana, los 3 percentiles principales, el valor máximo, mínimo y la desviación estandar
train_df.describe()

#Se revisan cuantos datos tiene cada variable numérica, la mediana, los 3 percentiles principales, el valor máximo, mínimo y la desviación estandar
test_df.describe()

#Se realiza un análisis exploratorio de los datos faltantes, como resultado se obtiene que 4 variables tienen mas del 20% de datos faltantes,
#dos de ellas son variables categoricas y dos de ellas son variables numericas
missing_values_train = train_df.isnull().sum()
missing_percentage_train =(missing_values_train / len(train_df))*100
pd.concat([missing_values_train,missing_percentage_train], axis=1, keys =['Missing Values', 'Percentage'])

# Se realiza el mismo proceso para el conjutno de test pero no muestra valores faltantes
missing_values_test = test_df.isnull().sum()
missing_percentage_test =(missing_values_test / len(test_df))*100
pd.concat([missing_values_test,missing_percentage_test], axis=1, keys =['Missing Values', 'Percentage'])

# Se realiza un avisualización de los datos de las variables numéricas por medio de histogramas
numeric_columns= train_df.select_dtypes(include=['float64','int64'])
for column in numeric_columns.columns:
  plt.figure(figsize=(8,6))
  sns.distplot(train_df[column], kde=False)
  plt.title(f'Histogram of {column}')
  plt.xlabel(column)
  plt.ylabel('Frequency')
  plt.show()

# Para la visualización de datos de las avriables categóricas se realiza un conteo de los valores en cada una de las variables
categorical_columns = train_df.select_dtypes(include=['object'])
for column in categorical_columns.columns:
  print(train_df[column].value_counts())

#Por ultimo se realiza un análisis de correlación entre las variables
correlation_matrix = train_df.corr()

plt.figure(figsize=(10,8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation map')
plt.show()

"""#### Manejo de datos faltantes"""

#Ya que 4 variables muestran mas del 20% de datos faltantes se decide completar estos espacios con simpleimputer de sklearn, utilizando la media; ya que los histpgramas muestran una relación
# similar a la campana de gauss
imputer = SimpleImputer(strategy='mean')
train_df[numeric_columns.columns] = imputer.fit_transform(train_df[numeric_columns.columns])

#Se comprueba que no haya valores faltantes
missing_values_train = train_df.isnull().sum()
missing_percentage_train =(missing_values_train / len(train_df))*100
pd.concat([missing_values_train,missing_percentage_train], axis=1, keys =['Missing Values', 'Percentage'])

# Debido a que las variables categoricas poseen varios valores distintos y al utilizar tecnicas como one hot code se obtienen mas de 80.000 variables
# se decide eliminarlas
train_df = train_df.drop(categorical_columns.columns, axis=1)
test_df = test_df.drop(categorical_columns.columns, axis=1)

"""#### Prueba con varios modelos"""

#Se dividen los conjutos de train y test en los cuatro conjutos principales necesarios para el modelo
x_train= train_df.drop('Accidente', axis=1)
y_train= train_df['Accidente']

x_test= test_df.drop('Accidente', axis=1)
y_test= test_df['Accidente']

# Se prueban 4 modelos para predecir la avriable Accidente LogisticRegression, SVC, GradientBoostingClassifier y RandomForestClassifier
classifiers = [
               LogisticRegression(),
               SVC(),
               GradientBoostingClassifier()]

for clf in classifiers:
  clf.fit(x_train, y_train)
  y_pred =clf.predict(x_test)
  accuracy = accuracy_score(y_test, y_pred)
  print(f'{clf.__class__.__name__} -Accuracy: {accuracy}')

#El accuracy mas alto de los modelos es LogisticRegression por lo que se decide escoger este modleo como el final.
rf_classifier = RandomForestClassifier()
rf_classifier.fit(x_train, y_train)
y_pred_rf = rf_classifier.predict(x_test)
accuracy_rf =accuracy_score (y_test, y_pred_rf)
print(f'RandomForestClassifier - Accuracy: {accuracy_rf}')

